{"version":3,"sources":["../../server/scripts/cron.js"],"names":["express","require","cron","axios","console","log","Region","keywords","profiles","interval","find","distinct","err","results","error","exec","then","res","module","exports","twitter","host","port","schedule","apiurl","encodeURIComponent","JSON","stringify","get"],"mappings":";;AAAA,IAAMA,OAAO,GAAGC,OAAO,CAAC,SAAD,CAAvB;;AACA,IAAMC,IAAI,GAAGD,OAAO,CAAC,WAAD,CAApB;;AACA,IAAME,KAAK,GAAGF,OAAO,CAAC,OAAD,CAArB;AAEA;;;;;;;AAKAG,OAAO,CAACC,GAAR,CAAY,sCAAZ;;AAEA,IAAIC,MAAM,GAAGL,OAAO,CAAC,kBAAD,CAApB;;AAEA,IAAIM,QAAJ,C,CAEA;;AAEA,IAAIC,QAAQ,GAAG,CAAC,WAAD,EAAc,YAAd,CAAf,C,CACA;;AACA,IAAIC,QAAQ,GAAG,MAAf,C,CAAuB;;AAEvBH,MAAM,CAACI,IAAP,CAAY,EAAZ,EAAe,UAAf,EACKC,QADL,CACc,UADd,EAC0B,UAASC,GAAT,EAAcC,OAAd,EAAsB;AACxC,MAAGD,GAAH,EAAQ;AACJ,WAAOR,OAAO,CAACU,KAAR,CAAcF,GAAd,CAAP;AACH,GAFD,MAEO;AACHR,IAAAA,OAAO,CAACC,GAAR,CAAY,gBAAZ;AACH;AACJ,CAPL,EAQKU,IARL,GASKC,IATL,CASU,UAAAC,GAAG,EAAI;AACTV,EAAAA,QAAQ,GAAGU,GAAX;AACH,CAXL,WAYW,UAAAL,GAAG;AAAA,SAAIR,OAAO,CAACC,GAAR,CAAYO,GAAZ,CAAJ;AAAA,CAZd;AAeA;;;;;AAKAM,MAAM,CAACC,OAAP,GAAiB;AACbC,EAAAA,OAAO,EAAE,iBAASC,IAAT,EAAcC,IAAd,EAAoB;AAEzBpB,IAAAA,IAAI,CAACqB,QAAL,CAAc,aAAd,EAA6B,YAAW;AAEpC,UAAIC,MAAM,oBAAaH,IAAb,cAAqBC,IAArB,yCAAwDG,kBAAkB,CAACC,IAAI,CAACC,SAAL,CAAenB,QAAf,CAAD,CAA1E,uBAAiHC,QAAjH,uBAAsIgB,kBAAkB,CAACC,IAAI,CAACC,SAAL,CAAepB,QAAf,CAAD,CAAxJ,CAAV;AAEAH,MAAAA,OAAO,CAACC,GAAR,CAAY,uBAAZ,EAJoC,CAKpC;;AAEA,UAAIY,GAAG,GAAGd,KAAK,CAACyB,GAAN,CAAUJ,MAAV,CAAV;AAEA,aAAOP,GAAP;AACH,KAVD;AAWH;AAdY,CAAjB","sourcesContent":["const express = require('express');\r\nconst cron = require(\"node-cron\");\r\nconst axios = require(\"axios\");\r\n\r\n/*****\r\n * Twitter scraping variables\r\n * \r\n * TODO: Retrieve Twitter profiles from DB\r\n */\r\nconsole.log(\"Initiating CRON: Twitter scraping...\");\r\n\r\nvar Region = require('../models/Region');\r\n\r\nlet keywords;\r\n\r\n// TODO: Save Twitter profiles, interval in db to manage via an interface.\r\n\r\nlet profiles = ['ForexLive', 'LiveSquawk'];\r\n//let interval = 1200000000; // Every minute + slippage\r\nlet interval = 120000; // Every minute + slippage\r\n\r\nRegion.find({},'keywords')\r\n    .distinct('keywords', function(err, results){\r\n        if(err) {\r\n            return console.error(err);\r\n        } else {\r\n            console.log(\"Keywords found\");\r\n        }\r\n    })\r\n    .exec()\r\n    .then(res => {\r\n        keywords = res;\r\n    })\r\n    .catch(err => console.log(err));\r\n\r\n\r\n/***** ***** ***** ***** ***** *****\r\n * Cron handler\r\n * Schedule tasks to be run on the server  \r\n */\r\n\r\nmodule.exports = {\r\n    twitter: function(host,port) {\r\n        \r\n        cron.schedule(\"*/1 * * * *\", function() {\r\n\r\n            let apiurl = `http://${host}:${port}/api/twitterscraper?profile=${encodeURIComponent(JSON.stringify(profiles))}&interval=${interval}&keywords=${encodeURIComponent(JSON.stringify(keywords))}`;\r\n    \r\n            console.log(\"---------------------\");\r\n            //console.log(\"Running Cron Job: Twitter scraper on \",apiurl);\r\n            \r\n            let res = axios.get(apiurl);\r\n\r\n            return res;\r\n        })\r\n    }\r\n};\r\n\r\n"],"file":"cron.js"}